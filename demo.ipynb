{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Neuromorphic Spatiotemporal Optical Flow Demo\n",
        "\n",
        "This notebook provides a live demonstration of the neuromorphic optical flow approach for motion segmentation, as described in our paper. Here, we will walk through the setup, data loading, processing, and visualization of the results.\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 1. Setup Environment\n",
        "\n",
        "First, we need to clone the repository and install the required dependencies.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!git clone https://github.com/RTCartist/Neuromorphic-Spatiotemporal-Optical-Flow.git\n",
        "%cd Neuromorphic-Spatiotemporal-Optical-Flow\n",
        "%pip install -r requirements.txt\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 2. Import Libraries and Define Paths\n",
        "\n",
        "Now, let's import the necessary libraries and set up the paths to our data and output directories.\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 3. Core Functions\n",
        "\n",
        "Here are the core functions from the original scripts, which we will use to process the images and compute the optical flow.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import scipy.io\n",
        "from numba import njit\n",
        "import matplotlib.pyplot as plt\n",
        "import flow_viz\n",
        "\n",
        "# Data paths for the 'grasp' dataset\n",
        "RGB_PATH = 'data/grasp/RGB'\n",
        "MASK_PATH = 'data/grasp/gtmask'\n",
        "IMGLIST = 'data/grasp/imgs.txt'\n",
        "MEMMATPATH = 'data/grasp/constructed_3D_matrix.mat'\n",
        "\n",
        "# Output directory for results\n",
        "OUTPUT_DIR = 'output/grasp_seg_demo'\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# Parameters from optical_flow_seg.py\n",
        "MEMSIZE = 80\n",
        "OFFSET = 0\n",
        "EXTEND_HEIGHT_UPPER = 20\n",
        "EXTEND_HEIGHT_LOWER = 20\n",
        "EXTEND_WIDTH_LEFT = 20\n",
        "EXTEND_WIDTH_RIGHT = 20\n",
        "THRES = 250\n",
        "CONNECT = 4\n",
        "FLAG = 2\n",
        "PADDING = 20\n",
        "SEG_TH = 1\n",
        "\n",
        "farneback_params = {\n",
        "    'pyr_scale': 0.5,\n",
        "    'levels': 3,\n",
        "    'winsize': 15,\n",
        "    'iterations': 3,\n",
        "    'poly_n': 5,\n",
        "    'poly_sigma': 1.2,\n",
        "    'flags': 0\n",
        "}\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 4. Load Data\n",
        "\n",
        "We will load a pair of consecutive images from the `grasp` dataset and the corresponding memristor state data.\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 5. Compute Optical Flow and Perform Segmentation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@njit\n",
        "def update_transition_pic(prev_memristor, transition_pic, thres):\n",
        "    for i in range(prev_memristor.shape[0]):\n",
        "        for j in range(prev_memristor.shape[1]):\n",
        "            if prev_memristor[i, j] >= thres:\n",
        "                transition_pic[i, j] = 255\n",
        "    return transition_pic\n",
        "\n",
        "def process_merged_region(stats, rgbimg1, rgbimg2, flow, pixel_width, pixel_height):\n",
        "    h, w = rgbimg1.shape[:2]\n",
        "    x_min = min(stats[i, cv2.CC_STAT_LEFT] for i in range(1, len(stats)))\n",
        "    y_min = min(stats[i, cv2.CC_STAT_TOP] for i in range(1, len(stats)))\n",
        "    x_max = max(stats[i, cv2.CC_STAT_LEFT] + stats[i, cv2.CC_STAT_WIDTH] for i in range(1, len(stats)))\n",
        "    y_max = max(stats[i, cv2.CC_STAT_TOP] + stats[i, cv2.CC_STAT_HEIGHT] for i in range(1, len(stats)))\n",
        "    \n",
        "    x_start = max(x_min * pixel_width - EXTEND_WIDTH_LEFT, 0)\n",
        "    y_start = max(y_min * pixel_height - EXTEND_HEIGHT_UPPER, 0)\n",
        "    x_end = min(x_max * pixel_width + EXTEND_WIDTH_RIGHT, w)\n",
        "    y_end = min(y_max * pixel_height + EXTEND_HEIGHT_LOWER, h)\n",
        "    \n",
        "    prev_region = rgbimg1[y_start:y_end, x_start:x_end]\n",
        "    next_region = rgbimg2[y_start:y_end, x_start:x_end]\n",
        "\n",
        "    if prev_region.size > 0 and next_region.size > 0:\n",
        "        current_flow = cv2.calcOpticalFlowFarneback(prev_region, next_region, None, **farneback_params)\n",
        "        flow[y_start:y_end, x_start:x_end] = current_flow\n",
        " \n",
        "    return flow, (x_start, y_start, x_end, y_end)\n",
        "\n",
        "def opticalFlow3D(memimg1, memimg2, rgbimg1, rgbimg2, pixel_width, pixel_height):\n",
        "    h, w = rgbimg1.shape[:2]\n",
        "    flow = np.zeros((h, w, 2))\n",
        "    \n",
        "    transition_pic = np.zeros((int(h / pixel_height), int(w / pixel_width)))\n",
        "    transition_pic = update_transition_pic(memimg2, transition_pic, THRES)\n",
        "    transition_pic = transition_pic.astype(np.uint8)\n",
        "    \n",
        "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(transition_pic, connectivity=CONNECT)\n",
        "    \n",
        "    if num_labels <= 1:\n",
        "        return flow, (0,0,0,0), 1\n",
        "\n",
        "    flow, regions_info = process_merged_region(stats, rgbimg1, rgbimg2, flow, pixel_width, pixel_height)\n",
        "    return flow, regions_info, num_labels\n",
        "\n",
        "def process_flow_region(mag, ang):\n",
        "    region_hsv = np.zeros((*mag.shape, 3), dtype=np.uint8)\n",
        "    region_hsv[..., 1] = 255\n",
        "    region_hsv[..., 0] = ang * 180 / np.pi / 2\n",
        "    region_hsv[..., 2] = cv2.normalize(mag, None, 0, 255, cv2.NORM_MINMAX)\n",
        "    \n",
        "    bgr = cv2.cvtColor(region_hsv, cv2.COLOR_HSV2BGR)\n",
        "    gray = cv2.cvtColor(bgr, cv2.COLOR_BGR2GRAY)\n",
        "    \n",
        "    threshold = SEG_TH\n",
        "    _, binary = cv2.threshold(gray, threshold, 255, cv2.THRESH_BINARY)\n",
        "    \n",
        "    motion_mask = np.zeros_like(gray)\n",
        "    motion_mask[mag > threshold] = 255\n",
        "    \n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (10, 10))\n",
        "    for _ in range(5):\n",
        "        motion_mask = cv2.dilate(motion_mask, kernel)\n",
        "        motion_mask = cv2.erode(motion_mask, kernel)\n",
        "    \n",
        "    _, motion_binary = cv2.threshold(motion_mask, 1, 255, cv2.THRESH_BINARY)\n",
        "    \n",
        "    return motion_binary\n",
        "\n",
        "def task_results(prev_frame, next_frame, flow, num_labels, regions_info):\n",
        "    h, w = prev_frame.shape[:2]\n",
        "    motion_binary = np.zeros((h, w), dtype=np.uint8)\n",
        "\n",
        "    if num_labels > 1:\n",
        "        x_min, y_min, x_max, y_max = regions_info\n",
        "        flow_region = flow[y_min:y_max, x_min:x_max]\n",
        "        mag, ang = cv2.cartToPolar(flow_region[..., 0], flow_region[..., 1])\n",
        "        motion_binary[y_min:y_max, x_min:x_max] = process_flow_region(mag, ang)\n",
        "    \n",
        "    return motion_binary\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 6. Visualize the Results\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 4. Load Data\n",
        "\n",
        "We will load a pair of consecutive images from the `grasp` dataset and the corresponding memristor state data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(IMGLIST, 'r') as f:\n",
        "    imgs = f.read().splitlines()\n",
        "\n",
        "mem_data = scipy.io.loadmat(MEMMATPATH)\n",
        "mem_state = mem_data['constructed3DMatrix']\n",
        "\n",
        "rgbimages = [os.path.join(RGB_PATH, i) for i in imgs]\n",
        "rgbimages = sorted(rgbimages, key=lambda x: int(os.path.basename(x).split('.')[0]))\n",
        "\n",
        "# Let's process the first pair of images\n",
        "img_idx = 0\n",
        "\n",
        "mem_state1 = mem_state[:, :, OFFSET + img_idx].astype(np.double)\n",
        "mem_state2 = mem_state[:, :, OFFSET + img_idx + 1].astype(np.double)\n",
        "\n",
        "prev_frame = cv2.imread(rgbimages[img_idx])\n",
        "next_frame = cv2.imread(rgbimages[img_idx + 1])\n",
        "\n",
        "prev_frame_gray = cv2.cvtColor(prev_frame, cv2.COLOR_RGB2GRAY)\n",
        "next_frame_gray = cv2.cvtColor(next_frame, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "with np.errstate(divide='ignore', invalid='ignore'):\n",
        "    mem_state1_processed = -3366 / np.log10(mem_state1) - 306\n",
        "mem_state1_processed = np.clip(mem_state1_processed, 0, 255).astype(np.uint8)\n",
        "\n",
        "with np.errstate(divide='ignore', invalid='ignore'):\n",
        "    mem_state2_processed = -3366 / np.log10(mem_state2) - 306\n",
        "mem_state2_processed = np.clip(mem_state2_processed, 0, 255).astype(np.uint8)\n",
        "\n",
        "memimg1 = mem_state1_processed\n",
        "memimg2 = mem_state2_processed\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 5. Compute Optical Flow and Perform Segmentation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pixel_width = MEMSIZE\n",
        "pixel_height = MEMSIZE\n",
        "\n",
        "# Calculate neuromorphic optical flow\n",
        "flow, regions_info, num_labels = opticalFlow3D(memimg1, memimg2, prev_frame_gray, next_frame_gray, pixel_width, pixel_height)\n",
        "flow = -flow  # Invert for Farneback\n",
        "\n",
        "# Perform motion segmentation\n",
        "motion_binary = task_results(prev_frame, next_frame, flow, num_labels, regions_info)\n",
        "\n",
        "# For comparison, compute standard Farneback optical flow on the full image\n",
        "full_flow = cv2.calcOpticalFlowFarneback(prev_frame_gray, next_frame_gray, None, **farneback_params)\n",
        "full_flow = -full_flow\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 6. Visualize the Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize the results\n",
        "flow_img = flow_viz.flow_to_image(flow)\n",
        "full_flow_img = flow_viz.flow_to_image(full_flow)\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(20, 10))\n",
        "fig.suptitle('Neuromorphic Optical Flow Segmentation Demo', fontsize=16)\n",
        "\n",
        "axes[0, 0].imshow(cv2.cvtColor(prev_frame, cv2.COLOR_BGR2RGB))\n",
        "axes[0, 0].set_title('Previous Frame')\n",
        "axes[0, 0].axis('off')\n",
        "\n",
        "axes[0, 1].imshow(cv2.cvtColor(next_frame, cv2.COLOR_BGR2RGB))\n",
        "axes[0, 1].set_title('Next Frame')\n",
        "axes[0, 1].axis('off')\n",
        "\n",
        "axes[0, 2].imshow(memimg2, cmap='hot')\n",
        "axes[0, 2].set_title('Memristor State (Region of Interest)')\n",
        "axes[0, 2].axis('off')\n",
        "\n",
        "axes[1, 0].imshow(full_flow_img)\n",
        "axes[1, 0].set_title('Standard Optical Flow (Full Image)')\n",
        "axes[1, 0].axis('off')\n",
        "\n",
        "axes[1, 1].imshow(flow_img)\n",
        "axes[1, 1].set_title('Neuromorphic Optical Flow (ROI Only)')\n",
        "axes[1, 1].axis('off')\n",
        "\n",
        "axes[1, 2].imshow(motion_binary, cmap='gray')\n",
        "axes[1, 2].set_title('Final Motion Segmentation')\n",
        "axes[1, 2].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Save the result\n",
        "output_path = os.path.join(OUTPUT_DIR, 'segmentation_result.png')\n",
        "cv2.imwrite(output_path, motion_binary)\n",
        "print(f\"Segmentation mask saved to: {output_path}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
